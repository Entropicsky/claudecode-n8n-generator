<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/>

# Comprehensive Guide to Building n8n AI Agents & JSON Import Files

## Introduction to AI Agents in n8n

The AI Agent node in n8n represents a powerful automation component that enables creating intelligent, context-aware workflows that can interact with various tools and services while maintaining conversation history[^1][^2]. An AI agent operates as an autonomous system that perceives data, makes rational decisions, and takes actions to achieve specific goals within its environment[^3]. As of 2025, n8n's AI Agent capabilities have evolved significantly, offering enhanced flexibility through integrations with multiple LLM providers and robust tool connections[^4].

> **üìã Template Reference**: This guide includes references to 330+ real-world examples from the [awesome-n8n-templates](docs/awesome-n8n-templates/) repository. See the [Template Index](docs/n8n-templates-index.md) for a comprehensive catalog organized by use case and complexity.

![n8n AI Agent Workflow Architecture - Component Connections and Data Flow](https://pplx-res.cloudinary.com/image/upload/v1750892703/pplx_code_interpreter/522290ea_gci9bl.jpg)

n8n AI Agent Workflow Architecture - Component Connections and Data Flow

## AI Agent Node Architecture

The AI Agent node serves as the orchestration center of intelligent workflows in n8n, connecting to several critical sub-components that define its capabilities[^5]. At its core, the AI Agent requires a Chat Model to provide the reasoning engine, Memory to maintain conversation context, and Tools to perform actions and retrieve information[^6][^7]. This modular architecture allows for extensive customization while maintaining a consistent workflow structure across different use cases[^8].

### Required Components

Every AI Agent workflow requires at minimum[^9]:

1. A trigger node (typically Chat Trigger for conversational interfaces)[^10]
2. The AI Agent node itself (type: `@n8n/n8n-nodes-langchain.agent`)[^11]
3. A Chat Model sub-node (OpenAI, Anthropic, etc.)[^12]

The connection pattern flows from the trigger to the AI Agent, with sub-components connecting directly to the Agent through special connection types (ai_chatModel, ai_memory, ai_tool)[^13][^14].

## Basic Configuration

Setting up an AI Agent begins with configuring its core parameters, which define its behavior and capabilities[^15][^16]. The most fundamental settings include the prompt configuration, system message, and model selection[^17].

### Node Parameters

The AI Agent node offers numerous configuration options that control its behavior[^18][^19]:

1. **Prompt Configuration**: Determines how the user's input is handled - either taken from a previous node or defined directly in the agent[^20]
2. **System Message**: Defines the agent's personality, capabilities, and behavior guidelines[^21]
3. **Max Iterations**: Controls how many reasoning steps the agent can take (default: 10)[^22]
4. **Return Intermediate Steps**: When enabled, shows the agent's thought process and tool usage[^23]

### Chat Model Setup

The Chat Model sub-node provides the AI reasoning capabilities for your agent[^24]. When configuring this component, pay special attention to[^25]:

1. **Model Selection**: Choose the appropriate model based on your needs (e.g., gpt-4o for advanced reasoning, claude-3-5-sonnet for nuanced responses)[^26]
2. **Temperature**: Control randomness (0.0-1.0, lower for more deterministic outputs)[^27]
3. **Max Tokens**: Limit response length to manage costs and prevent excessive outputs[^28]

Recent testing indicates that while OpenAI models like GPT-4o excel with function calling capabilities, alternatives like Mistral, Claude, and Groq can also be effective with proper configuration[^29][^30].

## Memory Management

One of the most powerful features of n8n's AI Agent implementation is its flexible memory management, allowing agents to maintain context across interactions[^31]. Different memory types offer varying levels of persistence, scalability, and performance characteristics to match your specific use case requirements[^32][^33].

### Memory Types Comparison

n8n supports several memory types, each with distinct advantages for different deployment scenarios[^34]:

![Comparison of n8n AI Agent Memory Types - Features and Capabilities](https://pplx-res.cloudinary.com/image/upload/v1750892493/pplx_code_interpreter/f26c992f_neoxdl.jpg)

Comparison of n8n AI Agent Memory Types - Features and Capabilities

The choice of memory type significantly impacts both development experience and production performance[^35]. For testing and prototyping, Simple Memory provides the easiest setup, while Redis or Postgres Memory offer the scalability and persistence needed for production applications with multiple users[^36][^37].

### Session Management Best Practices

Effective session management is crucial for maintaining separate conversation contexts when dealing with multiple users[^38]. Key considerations include:

1. **Unique Session IDs**: Generate distinct identifiers for each user conversation, typically using UUIDs or user-specific identifiers[^39]
2. **Context Window Optimization**: Balance memory usage and context retention by adjusting the number of past interactions stored[^40]
3. **Session Expiration**: Implement timeout mechanisms for inactive sessions to free up resources[^41]

For multi-user applications, using database-backed memory (Postgres/Redis) allows for efficient session management across workflow executions[^42][^43].

## Workflow Static Data Pattern

A critical pattern for preserving data through AI Agent processing is the use of workflow static data. This pattern is essential when AI Agent nodes don't properly pass through input data, which is a common limitation in complex workflows.

### The Problem

AI Agent nodes often consume input data without passing it through to subsequent nodes. This creates challenges when you need to:
- Maintain original data alongside AI-generated content
- Process large datasets through AI agents
- Preserve metadata for later use

### The Solution: Static Data Pattern

Use `$getWorkflowStaticData()` and `$setWorkflowStaticData()` to store and retrieve data across workflow executions:

```javascript
// Store data before AI Agent processing
const companies = $input.all();
$setWorkflowStaticData({
  companies: companies,
  timestamp: new Date().toISOString()
});

// Retrieve data after AI Agent processing
const staticData = $getWorkflowStaticData();
const originalCompanies = staticData.companies;
```

### Real-World Implementation (Company News Newsletter v7.3.3)

This pattern was successfully used to handle 70+ companies through an AI summarization agent:

```json
{
  "name": "Store Company Data",
  "type": "n8n-nodes-base.code",
  "parameters": {
    "jsCode": "// Store all company data before AI processing\nconst allCompanies = $input.all();\n$setWorkflowStaticData({\n  companies: allCompanies,\n  processedAt: new Date().toISOString()\n});\n\nreturn allCompanies;"
  }
}
```

Then after AI processing:

```json
{
  "name": "Merge AI Results with Original Data",
  "type": "n8n-nodes-base.code",
  "parameters": {
    "jsCode": "// Retrieve original company data\nconst staticData = $getWorkflowStaticData();\nconst companies = staticData.companies;\nconst aiSummaries = $input.all();\n\n// Merge AI summaries with original data\nreturn companies.map((company, index) => ({\n  ...company.json,\n  aiSummary: aiSummaries[index]?.json?.summary || ''\n}));"
  }
}
```

### Best Practices

1. **Store Early**: Save data immediately after retrieval, before any AI processing
2. **Include Metadata**: Add timestamps and processing flags
3. **Clear When Done**: Reset static data at workflow end to prevent memory issues
4. **Handle Large Datasets**: Consider chunking for very large datasets

## Tool Integration

Tools extend the AI Agent's capabilities beyond conversation, enabling it to retrieve information and take actions in external systems[^44]. As of 2025, n8n supports a diverse ecosystem of tool types that can be connected to AI Agents, making them remarkably versatile[^45][^46].

![n8n AI Agent Tools Taxonomy - Categories and Capabilities](https://pplx-res.cloudinary.com/image/upload/v1750893052/pplx_code_interpreter/35181aee_c5lisg.jpg)

n8n AI Agent Tools Taxonomy - Categories and Capabilities

### Tool Configuration

When adding tools to your AI Agent, follow these key practices[^47]:

1. **Descriptive Naming**: Give tools clear, action-oriented names that indicate their purpose[^48]
2. **Detailed Descriptions**: Provide comprehensive descriptions to help the AI understand when and how to use each tool[^49]
3. **Parameter Design**: Define input schemas carefully, using the `$fromAI()` function for dynamic parameter values[^50]

The quality of tool descriptions directly impacts the agent's ability to select and use tools appropriately[^51]. Poor descriptions often lead to tool selection errors or redundant calls[^52].

### Advanced Tool Features

Recent updates to n8n have introduced several advanced tool capabilities[^53]:

1. **Extended HTTP Request Tool**: Full support for all HTTP Request node options, including pagination, batching, timeout, and proxy support[^54]
2. **Partial Tool Execution**: Test specific tools without running the entire agent workflow (added in v1.92.0)[^55]
3. **Vector Store Integration**: Direct connection to vector databases for RAG (Retrieval Augmented Generation) applications[^56]
4. **Model Context Protocol (MCP)**: Standardized protocol for AI model interactions with tools (added in v1.88.0)[^57]

The MCP Client Tool, in particular, represents a significant advancement, allowing agents to discover and execute tools dynamically across different platforms without complex integration code[^58][^59].

## Building n8n JSON Import Files for AI Agents

Creating JSON files for n8n AI Agent workflows requires understanding both the structural patterns and best practices derived from successful implementations. This section provides comprehensive guidance for building import-ready JSON files.

### JSON Structure Fundamentals

Every n8n AI Agent workflow JSON follows this core structure[^60][^61]:

```json
{
  "name": "Your Workflow Name",
  "nodes": [],
  "connections": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 1,
  "updatedAt": "2025-01-01T00:00:00.000Z",
  "versionId": "unique-version-id"
}
```

### Essential Node Types for AI Agents

#### 1. Trigger Nodes
```json
{
  "parameters": {
    "mode": "lastNode",
    "options": {}
  },
  "id": "unique-node-id",
  "name": "When chat message received",
  "type": "@n8n/n8n-nodes-langchain.chatTrigger",
  "typeVersion": 1.1,
  "position": [140, 240]
}
```

#### 2. AI Agent Node
```json
{
  "parameters": {
    "options": {
      "systemMessage": "=You are a helpful AI assistant. Current date: {{ DateTime.local().toFormat('cccc d LLLL yyyy') }}.",
      "maxIterations": 10,
      "returnIntermediateSteps": false
    }
  },
  "id": "agent-node-id",
  "name": "AI Agent",
  "type": "@n8n/n8n-nodes-langchain.agent",
  "typeVersion": 1.7,
  "position": [360, 240]
}
```

#### 3. Chat Model Node
```json
{
  "parameters": {
    "options": {
      "temperature": 0.1,
      "maxTokens": 2000
    }
  },
  "id": "model-node-id",
  "name": "OpenAI Chat Model",
  "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
  "typeVersion": 1.9,
  "position": [360, 420],
  "credentials": {
    "openAiApi": {
      "id": "credential-id",
      "name": "OpenAi account"
    }
  }
}
```

### Connection Patterns

AI Agent workflows use special connection types:

```json
"connections": {
  "When chat message received": {
    "main": [[{"node": "AI Agent", "type": "main", "index": 0}]]
  },
  "OpenAI Chat Model": {
    "ai_languageModel": [[{"node": "AI Agent", "type": "ai_languageModel", "index": 0}]]
  },
  "Buffer Memory": {
    "ai_memory": [[{"node": "AI Agent", "type": "ai_memory", "index": 0}]]
  },
  "Tool Node": {
    "ai_tool": [[{"node": "AI Agent", "type": "ai_tool", "index": 0}]]
  }
}
```

### Complete Production-Ready Example

**Customer Support AI Agent with Multiple Tools:**

```json
{
  "name": "Customer Support AI Agent",
  "nodes": [
    {
      "parameters": {"mode": "lastNode"},
      "id": "chat-trigger",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [140, 240]
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "You are a customer support agent. Use available tools to help customers with their inquiries. Current date: {{ DateTime.local().toFormat('cccc d LLLL yyyy') }}.",
          "maxIterations": 5,
          "returnIntermediateSteps": false
        }
      },
      "id": "ai-agent",
      "name": "Customer Support Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [360, 240]
    },
    {
      "parameters": {
        "options": {"temperature": 0.1}
      },
      "id": "openai-model",
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.9,
      "position": [360, 420],
      "credentials": {
        "openAiApi": {"id": "openai-cred-id", "name": "OpenAI"}
      }
    },
    {
      "parameters": {"contextWindowLength": 10},
      "id": "buffer-memory",
      "name": "Chat Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.2,
      "position": [580, 240]
    },
    {
      "parameters": {
        "name": "get_order_status",
        "description": "Get the current status of a customer order by order number",
        "workflowId": "order-lookup-workflow-id",
        "fields": {
          "values": [
            {
              "name": "order_number",
              "description": "The order number to look up",
              "type": "string",
              "value": "={{ $fromAI('order_number', 'The customer order number') }}"
            }
          ]
        }
      },
      "id": "order-tool",
      "name": "Order Lookup Tool",
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 1.1,
      "position": [580, 420]
    }
  ],
  "connections": {
    "When chat message received": {
      "main": [[{"node": "Customer Support Agent", "type": "main", "index": 0}]]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [[{"node": "Customer Support Agent", "type": "ai_languageModel", "index": 0}]]
    },
    "Chat Memory": {
      "ai_memory": [[{"node": "Customer Support Agent", "type": "ai_memory", "index": 0}]]
    },
    "Order Lookup Tool": {
      "ai_tool": [[{"node": "Customer Support Agent", "type": "ai_tool", "index": 0}]]
    }
  },
  "settings": {"executionOrder": "v1"},
  "staticData": null,
  "tags": ["customer-support", "ai-agent"],
  "triggerCount": 1,
  "updatedAt": "2025-01-01T00:00:00.000Z",
  "versionId": "unique-version-id"
}
```

### JSON Creation Checklist

**Before Import:**
- [ ] Replace all placeholder IDs with valid UUIDs
- [ ] Update credential references to match your n8n instance
- [ ] Verify workflow IDs for Tool Workflow nodes exist
- [ ] Test system messages for clarity and completeness
- [ ] Validate connection structure (especially ai_* connections)
- [ ] Set appropriate position coordinates for visual layout

**After Import:**
- [ ] Test all credential connections
- [ ] Verify tool functionality
- [ ] Validate memory persistence (if using database memory)
- [ ] Test conversation flow end-to-end
- [ ] Monitor token usage and adjust model parameters if needed

## Troubleshooting Common Issues

AI Agent workflows can encounter various issues during development and production. Understanding common error patterns and their solutions can significantly reduce debugging time.

### Configuration Errors

The most frequent issues occur during initial setup and configuration[^63]:

### Runtime Issues

Once configured, agents may encounter runtime issues related to tool execution, memory management, or model limitations[^64]. Common problems include agents getting stuck in loops, reaching maximum iterations, or failing to use tools effectively[^65][^66]. These issues typically stem from unclear tool descriptions, poor prompt engineering, or model compatibility problems[^67].

## Advanced Scenarios and Best Practices

As AI Agent capabilities have evolved, several advanced patterns have emerged for building sophisticated applications[^68][^69].

### Multi-Stage AI Agent Workflows

Complex tasks often benefit from sequential AI agents, each specialized for a specific role. This pattern divides complex processes into manageable stages with focused responsibilities.

#### Pattern: Research ‚Üí Script ‚Üí Action

Example from HeyGen Video Automation:

```json
// Stage 1: Research Agent
{
  "name": "Research Agent",
  "type": "@n8n/n8n-nodes-langchain.agent",
  "parameters": {
    "options": {
      "systemMessage": "You are a research specialist. Your job is to gather comprehensive information about the given topic using available tools. Focus on facts, statistics, and key insights."
    }
  }
}

// Stage 2: Scriptwriting Agent
{
  "name": "Script Writer",
  "type": "@n8n/n8n-nodes-langchain.agent",
  "parameters": {
    "options": {
      "systemMessage": "You are a professional scriptwriter. Transform the research into an engaging video script. Include hooks, transitions, and a strong call-to-action."
    }
  }
}

// Stage 3: Action Agent
{
  "name": "Video Creation Agent",
  "type": "@n8n/n8n-nodes-langchain.agent",
  "parameters": {
    "options": {
      "systemMessage": "You are responsible for creating the video using HeyGen API. Format the script appropriately and handle the technical implementation."
    }
  }
}
```

#### Best Practices for Multi-Stage Workflows

1. **Clear Role Definition**: Each agent should have a single, well-defined purpose
2. **Data Handoff**: Use structured formats for passing data between agents
3. **Error Boundaries**: Each stage should handle its own errors gracefully
4. **Progress Tracking**: Implement logging at each stage for debugging

### RAG Implementation

Retrieval Augmented Generation (RAG) represents one of the most powerful AI Agent patterns, combining vector databases with AI reasoning[^70]. The implementation involves:

1. Processing documents into vector embeddings
2. Storing them in a vector database (Pinecone, Weaviate, etc.)
3. Connecting the Vector Store Tool to your AI Agent
4. Configuring prompts to effectively use retrieved information

This pattern enables agents to access domain-specific knowledge beyond their training data, resulting in more accurate and contextual responses.

### Multi-Agent Systems

Advanced workflows can implement multi-agent architectures where specialized agents collaborate on complex tasks. Patterns include:

1. **Hierarchical**: A supervisor agent coordinates specialized worker agents
2. **Sequential**: Agents process information in a pipeline, each adding value
3. **Parallel**: Multiple agents work simultaneously on different aspects of a problem

These patterns are particularly effective for complex business processes requiring different expertise domains and tool access.

### Performance Optimization

For production deployments, optimizing AI Agent performance is crucial:

1. **Model Selection**: Use the most efficient model for your specific needs
2. **Token Management**: Optimize prompts and memory to reduce token usage
3. **Caching**: Implement response caching for common queries
4. **Parallel Processing**: Use multiple agents for high-volume workloads

Recent benchmarks suggest that carefully optimized agent workflows can achieve 3-5x performance improvements while reducing costs by 40-60%.

## Data Flow Resilience Patterns

Handling large datasets requires careful consideration of service limits and data flow patterns. These patterns ensure your workflows remain robust when processing significant data volumes.

### Handling Service Limits

#### Google Sheets 50K Character Limit

When working with Google Sheets, the 50,000 character cell limit requires creative solutions:

```json
{
  "name": "Split Large Dataset",
  "type": "n8n-nodes-base.code",
  "parameters": {
    "jsCode": "// Separate metadata from data rows\nconst companies = $input.all();\nconst metadata = {\n  count: companies.length,\n  fields: Object.keys(companies[0].json),\n  processedAt: new Date().toISOString()\n};\n\n// Store metadata separately\nconst metadataRow = [JSON.stringify(metadata)];\n\n// Process companies in batches\nconst batchSize = 10;\nconst batches = [];\nfor (let i = 0; i < companies.length; i += batchSize) {\n  const batch = companies.slice(i, i + batchSize);\n  batches.push(batch.map(c => JSON.stringify(c.json)));\n}\n\nreturn {\n  metadata: metadataRow,\n  batches: batches\n};"
  }
}
```

### Dynamic Field Detection

Robust workflows must handle varying field names across different data sources:

```json
{
  "name": "Normalize Field Names",
  "type": "n8n-nodes-base.code",
  "parameters": {
    "jsCode": "// Handle field name variations\nconst items = $input.all();\n\nconst fieldMappings = {\n  company: ['Company', 'company', 'CompanyName', 'company_name'],\n  email: ['Email', 'email', 'EmailAddress', 'email_address', 'Recipient'],\n  name: ['Name', 'name', 'FullName', 'full_name', 'ContactName']\n};\n\nfunction findField(item, fieldNames) {\n  for (const fieldName of fieldNames) {\n    if (item.json[fieldName] !== undefined) {\n      return item.json[fieldName];\n    }\n  }\n  return null;\n}\n\nreturn items.map(item => ({\n  company: findField(item, fieldMappings.company),\n  email: findField(item, fieldMappings.email),\n  name: findField(item, fieldMappings.name),\n  original: item.json\n}));"
  }
}
```

### Batch Processing Strategy

For datasets with 70+ items, implement intelligent batching:

1. **Size-Based Batching**: Process fixed number of items per batch
2. **Time-Based Batching**: Process for fixed duration then pause
3. **Memory-Based Batching**: Monitor memory usage and batch accordingly
4. **API Limit Batching**: Respect rate limits with strategic pauses

## Sub-Workflows and Modular Design

Sub-workflows allow you to break complex AI Agent workflows into smaller, reusable components. This modular approach improves maintainability and enables workflow reuse across different projects.

### Execute Workflow Node

The Execute Workflow node enables calling sub-workflows from main workflows:

```json
{
  "name": "Execute Sub-workflow",
  "type": "n8n-nodes-base.executeWorkflow",
  "parameters": {
    "source": "database",
    "workflowId": "sub-workflow-id",
    "waitForExecution": true
  },
  "typeVersion": 1
}
```

### Sub-workflow as AI Tool

For AI Agents, sub-workflows are often used as tools via the Tool Workflow node:

```json
{
  "name": "Research Tool",
  "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
  "parameters": {
    "name": "web_research",
    "description": "Conduct web research on a given topic and return findings",
    "workflowId": "research-workflow-id",
    "fields": {
      "values": [
        {
          "name": "topic",
          "description": "The research topic or query",
          "type": "string",
          "value": "={{ $fromAI('topic', 'Research topic to investigate') }}"
        }
      ]
    }
  },
  "typeVersion": 1.1
}
```

### Sub-workflow Trigger Configuration

Sub-workflows must include an Execute Workflow Trigger:

```json
{
  "name": "When Executed by Another Workflow",
  "type": "n8n-nodes-base.executeWorkflowTrigger",
  "parameters": {
    "respondWith": "allEntries",
    "responseMode": "responseNode"
  },
  "typeVersion": 1
}
```

### Best Practices for Sub-workflows

1. **Single Responsibility**: Each sub-workflow should handle one specific task
2. **Clear Input/Output**: Define consistent data structures for inputs and outputs
3. **Error Handling**: Include proper error handling and fallback mechanisms
4. **Documentation**: Use sticky notes to document sub-workflow purpose and usage
5. **Testing**: Test sub-workflows independently before integrating

## Flow Control Components

Flow control nodes enable complex logic, conditional processing, and data manipulation in AI Agent workflows.

### Loop Over Items (Split In Batches)

Process large datasets in manageable batches:

```json
{
  "name": "Process in Batches",
  "type": "n8n-nodes-base.splitInBatches",
  "parameters": {
    "batchSize": 10,
    "options": {
      "reset": false
    }
  },
  "typeVersion": 3
}
```

**Common Pattern: AI Processing with Batching**
```
Data Source ‚Üí Split In Batches ‚Üí AI Agent Processing ‚Üí Merge Results ‚Üí Final Output
```

### Conditional Logic (If Node)

Implement decision trees and conditional processing:

```json
{
  "name": "Check User Intent",
  "type": "n8n-nodes-base.if",
  "parameters": {
    "conditions": {
      "combinator": "and",
      "conditions": [
        {
          "operator": {
            "type": "string",
            "operation": "contains"
          },
          "leftValue": "={{ $json.chatInput }}",
          "rightValue": "order"
        }
      ]
    }
  },
  "typeVersion": 2
}
```

### Switch Node for Multi-Path Routing

Route data based on multiple conditions:

```json
{
  "name": "Route by Command",
  "type": "n8n-nodes-base.switch",
  "parameters": {
    "dataType": "string",
    "value1": "={{ $json.command }}",
    "rules": {
      "rules": [
        {
          "value2": "help",
          "operation": "equal",
          "output": 1
        },
        {
          "value2": "search",
          "operation": "equal",
          "output": 2
        },
        {
          "value2": "order",
          "operation": "equal",
          "output": 3
        }
      ]
    },
    "fallbackOutput": 4
  },
  "typeVersion": 3
}
```

### Merge Node for Data Combination

Combine data from multiple sources:

```json
{
  "name": "Merge Customer Data",
  "type": "n8n-nodes-base.merge",
  "parameters": {
    "mode": "combine",
    "joinMode": "enrichInput2",
    "mergeByFields": {
      "values": [
        {
          "field1": "customer_id",
          "field2": "id"
        }
      ]
    }
  },
  "typeVersion": 3
}
```

### Wait Node for Delays and Timing

Add delays for rate limiting or user experience:

```json
{
  "name": "Wait for Response",
  "type": "n8n-nodes-base.wait",
  "parameters": {
    "amount": 5,
    "unit": "seconds"
  },
  "typeVersion": 1.1
}
```

### Split Out Node for Array Processing

Process individual items from arrays:

```json
{
  "name": "Split Items",
  "type": "n8n-nodes-base.splitOut",
  "parameters": {
    "fieldToSplitOut": "results",
    "options": {
      "destinationFieldName": "item"
    }
  },
  "typeVersion": 1
}
```

### Common Flow Control Patterns

**Pattern 1: Conditional AI Processing**
```
Input ‚Üí If (Check Condition) ‚Üí AI Agent (True Path) ‚Üí Output
                              ‚Üí Direct Response (False Path) ‚Üí
```

**Pattern 2: Batch Processing with AI**
```
Data ‚Üí Split In Batches ‚Üí AI Processing ‚Üí Merge ‚Üí Final Output
```

**Pattern 3: Multi-Command Router**
```
Input ‚Üí Switch (Route by Command) ‚Üí Help Agent (Output 1)
                                  ‚Üí Search Agent (Output 2)
                                  ‚Üí Order Agent (Output 3)
                                  ‚Üí Default Agent (Fallback)
```

## Workflow Documentation with Sticky Notes

Sticky notes are essential for creating well-documented, maintainable AI Agent workflows. They provide context and instructions without affecting workflow execution.

### Sticky Note JSON Structure

```json
{
  "id": "unique-sticky-note-id",
  "name": "Sticky Note",
  "type": "n8n-nodes-base.stickyNote",
  "position": [x, y],
  "parameters": {
    "width": 400,
    "height": 300,
    "content": "## Section Title\n\nMarkdown formatted content here\n\n* Bullet point 1\n* Bullet point 2\n\n[Link to documentation](https://example.com)"
  },
  "typeVersion": 1
}
```

### Documentation Patterns

**Setup Instructions:**
```json
{
  "parameters": {
    "width": 442,
    "height": 360,
    "content": "### 1. Setup Requirements\n\n* Configure OpenAI API credentials\n* Set up database connection\n* Install required dependencies\n\n**Important**: Replace placeholder values with your actual credentials"
  }
}
```

**Section Headers:**
```json
{
  "parameters": {
    "width": 330,
    "height": 150,
    "content": "## Data Processing Section\n\n### Handles customer data validation and enrichment"
  }
}
```

**Process Flow Documentation:**
```json
{
  "parameters": {
    "width": 471,
    "height": 322,
    "content": "### 2. AI Agent Processing\n\n* **System Message**: Defines agent behavior\n* **Tools**: Available actions for the agent\n* **Memory**: Maintains conversation context\n\n**Output**: Structured response with action taken"
  }
}
```

### Best Practices for Sticky Notes

1. **Positioning**: Place notes near related nodes for context
2. **Markdown Formatting**: Use headers, lists, and links for clarity
3. **Color Coding** (via content structure):
   - Setup instructions: Use numbered headers
   - Warnings: Use bold text with **Important** prefix
   - Process explanations: Use bullet points
4. **Sequential Naming**: "Sticky Note", "Sticky Note1", "Sticky Note2"
5. **Appropriate Sizing**: Width 300-500px, height based on content

### Sticky Note Templates

**Workflow Overview:**
```markdown
# AI Customer Support Agent

## Purpose
Automated customer support with order lookup and FAQ capabilities

## Key Features
* Natural language processing
* Order status checking
* Knowledge base integration
* Escalation to human agents
```

**Configuration Guide:**
```markdown
### Configuration Required

1. **Credentials**:
   - OpenAI API Key
   - Database connection
   - Email service (optional)

2. **Environment Variables**:
   - `SUPPORT_EMAIL`: For escalations
   - `DB_CONNECTION_STRING`: Database URL

**‚ö†Ô∏è Important**: Test all connections before deploying
```

**Troubleshooting Notes:**
```markdown
## Common Issues

* **Agent not responding**: Check OpenAI credits
* **Database errors**: Verify connection string
* **Tool failures**: Review tool descriptions

### Debug Steps
1. Check execution logs
2. Verify input data format
3. Test tools individually
```

## n8n Template Reference Library

### Quick Access by Use Case

**Customer Service & Support** *(45+ examples)*
- [AI-powered email processing autoresponder](docs/awesome-n8n-templates/Gmail_and_Email_Automation/AI-powered%20email%20processing%20autoresponder%20and%20response%20approval%20(Yes_No).txt)
- [Customer Support Channel and Ticketing System with Slack](docs/awesome-n8n-templates/Slack/Customer%20Support%20Channel%20and%20Ticketing%20System%20with%20Slack%20and%20Linear.txt)
- [AI-powered WooCommerce Support-Agent](docs/awesome-n8n-templates/OpenAI_and_LLMs/AI-powered%20WooCommerce%20Support-Agent.txt)
- [Complete business WhatsApp AI-Powered RAG Chatbot](docs/awesome-n8n-templates/WhatsApp/Complete%20business%20WhatsApp%20AI-Powered%20RAG%20Chatbot%20using%20OpenAI.txt)

**Data Analysis & Research** *(35+ examples)*
- [Open Deep Research - AI-Powered Autonomous Research Workflow](docs/awesome-n8n-templates/AI_Research_RAG_and_Data_Analysis/Open%20Deep%20Research%20-%20AI-Powered%20Autonomous%20Research%20Workflow.txt)
- [Host Your Own AI Deep Research Agent](docs/awesome-n8n-templates/AI_Research_RAG_and_Data_Analysis/Host%20Your%20Own%20AI%20Deep%20Research%20Agent%20with%20n8n,%20Apify%20and%20OpenAI%20o3.txt)
- [AI Agent to chat with Supabase/PostgreSQL DB](docs/awesome-n8n-templates/OpenAI_and_LLMs/AI%20Agent%20to%20chat%20with%20Supabase_PostgreSQL%20DB.txt)

**Content Creation & Marketing** *(40+ examples)*
- [AI Social Media Caption Creator](docs/awesome-n8n-templates/OpenAI_and_LLMs/AI%20Social%20Media%20Caption%20Creator%20creates%20social%20media%20post%20captions%20in%20Airtable.txt)
- [Generate Instagram Content from Top Trends](docs/awesome-n8n-templates/Instagram_Twitter_Social_Media/Generate%20Instagram%20Content%20from%20Top%20Trends%20with%20AI%20Image%20Generation.txt)
- [Automate Blog Creation in Brand Voice with AI](docs/awesome-n8n-templates/WordPress/Automate%20Blog%20Creation%20in%20Brand%20Voice%20with%20AI.txt)

**RAG & Knowledge Management** *(25+ examples)*
- [RAG Chatbot for Company Documents using Google Drive](docs/awesome-n8n-templates/Google_Drive_and_Google_Sheets/RAG%20Chatbot%20for%20Company%20Documents%20using%20Google%20Drive%20and%20Gemini.txt)
- [Chat with GitHub API Documentation](docs/awesome-n8n-templates/AI_Research_RAG_and_Data_Analysis/Chat%20with%20GitHub%20API%20Documentation_%20RAG-Powered%20Chatbot%20with%20Pinecone%20&%20OpenAI.txt)
- [Notion knowledge base AI assistant](docs/awesome-n8n-templates/Notion/Notion%20knowledge%20base%20AI%20assistant.txt)

### Advanced Implementation Patterns

**Multi-Modal AI Agents**
- Vision-based processing: `AI-Powered Children's Arabic Storytelling on Telegram`
- Audio processing: `Translate Telegram audio messages with AI`
- Document analysis: `CV Resume PDF Parsing with Multimodal Vision AI`

**Multi-Agent Systems**
- Specialized agents: `AI Crew to Automate Fundamental Stock Analysis`
- Pipeline processing: `AI Agent for realtime insights on meetings`
- Hierarchical workflows: `Advanced AI Demo (Presented at AI Developers #14 meetup)`

**Production Deployment Examples**
- Session management: `Telegram Bot with Supabase memory and OpenAI assistant`
- Scalable memory: `AI Agent Chatbot + LONG TERM Memory + Note Storage`
- Multi-user support: `Turn Emails into AI-Enhanced Tasks in Notion (Multi-User Support)`

### Template Complexity Guide

**üü¢ Simple (Great for Learning)**
- Basic chat interfaces
- Single-tool integrations
- Simple memory management
- *Examples: Basic Telegram Bot, Simple Email Responder*

**üü° Medium (Production Ready)**
- Multi-tool workflows
- Database integrations
- Advanced prompting
- *Examples: Customer Support Agent, Content Creation Pipeline*

**üî¥ Advanced (Enterprise Solutions)**
- Multi-agent systems
- Complex RAG implementations
- Real-time processing
- *Examples: Deep Research Agent, Multi-Modal Analysis*

### Quick Start Templates by Technology

**OpenAI Integration**
- Start with: `AI agent chat.txt`
- Advanced: `OpenAI assistant with custom tools.txt`

**Database Chat**
- PostgreSQL: `Chat with Postgresql Database.txt`
- MongoDB: `MongoDB AI Agent - Intelligent Movie Recommendations.txt`
- Supabase: `AI Agent to chat with Supabase_PostgreSQL DB.txt`

**Platform Integration**
- Slack: `IT Ops AI SlackBot Workflow - Chat with your knowledge base.txt`
- Discord: `Discord AI-powered bot.txt`
- Telegram: `Telegram AI bot assistant_ ready-made template.txt`

> **üí° Pro Tip**: Always start with a simpler template and gradually add complexity. The template index includes complexity ratings to help you choose the right starting point.

## Multi-Stage AI Agent Workflows

Multi-stage AI Agent workflows represent a powerful pattern where specialized agents handle different phases of a complex task. This approach improves quality by allowing each agent to focus on its specific expertise.

### Pattern Overview

```
Trigger ‚Üí Research Agent ‚Üí Scriptwriting Agent ‚Üí Content Generation ‚Üí Output
         ‚Üì                ‚Üì                      ‚Üì
    (Gather Data)    (Process Data)        (Create Output)
```

### Real-World Example: HeyGen Video Automation

This workflow demonstrates three specialized agents working in sequence:

1. **Research Agent**: Searches Reddit for marketing insights
2. **Scriptwriting Agent**: Creates video scripts from research
3. **Video Creator**: Generates avatar videos from scripts

```json
{
  "name": "Research Agent",
  "type": "@n8n/n8n-nodes-langchain.agent",
  "parameters": {
    "options": {
      "systemMessage": "Search Reddit for the keyword I give you\nFind relevant marketing insights and generate content concepts.\n\nUse the firecrawl tool for the search."
    }
  }
}
```

### Best Practices for Multi-Stage Workflows

1. **Clear Stage Separation**: Each agent should have a distinct purpose
2. **Data Handoff**: Use structured output formats between stages
3. **Progressive Enhancement**: Each stage builds on the previous
4. **Error Boundaries**: Implement fallbacks between stages
5. **Stage Documentation**: Use sticky notes to label each phase

### Common Multi-Stage Patterns

**Research ‚Üí Analysis ‚Üí Action**
- Stage 1: Gather information from multiple sources
- Stage 2: Analyze and synthesize findings
- Stage 3: Take action based on analysis

**Draft ‚Üí Review ‚Üí Publish**
- Stage 1: Generate initial content
- Stage 2: Review and refine with different criteria
- Stage 3: Format and publish final version

**Extract ‚Üí Transform ‚Üí Load (ETL)**
- Stage 1: Extract data from various sources
- Stage 2: Transform and enrich with AI
- Stage 3: Load into destination systems

## Data Flow Resilience Patterns

When processing large datasets through AI agents, data resilience becomes critical. These patterns ensure data integrity and handle common limitations.

### Google Sheets 50,000 Character Limit

Google Sheets cells have a 50,000 character limit, which can cause issues when storing AI-generated content:

**Problem**: AI summaries for multiple companies exceed cell limits
**Solution**: Split content across multiple cells or use metadata separation

```javascript
// Check content length before writing
const content = aiResult.summary;
if (content.length > 45000) { // Leave buffer
  // Split into chunks or store in separate cells
  const chunks = content.match(/.{1,45000}/g);
  return chunks.map((chunk, index) => ({
    company: companyName,
    summaryPart: index + 1,
    content: chunk
  }));
}
```

### Metadata Separation Pattern

Separate metadata from content to avoid data loss:

```json
{
  "name": "Split Company Data",
  "parameters": {
    "jsCode": "// Separate metadata from AI content\nreturn {\n  metadata: {\n    company: $json.company,\n    weekNumber: $json.weekNumber,\n    timestamp: $json.timestamp\n  },\n  content: {\n    summary: $json.aiSummary,\n    links: $json.links\n  }\n};"
  }
}
```

### Batch Processing Strategies

**For 70+ Company Processing**:
1. Process in batches of 10-20 companies
2. Store intermediate results
3. Implement retry logic for failures
4. Use workflow static data for state management

### Dynamic Field Detection

Handle field name variations across different data sources:

```javascript
// Detect company field dynamically
const companyField = Object.keys($json).find(key => 
  key.toLowerCase().includes('company') || 
  key.toLowerCase().includes('organization')
);

const emailField = Object.keys($json).find(key => 
  key.toLowerCase().includes('email') || 
  key.toLowerCase().includes('recipient')
);
```

## Complex Data Processing Patterns

These patterns handle sophisticated data flows involving multiple data types, parallel processing, and aggregation.

### Binary Data Processing

Handle attachments and files through AI workflows:

```json
{
  "name": "Process Attachments",
  "type": "n8n-nodes-base.switch",
  "parameters": {
    "dataType": "string",
    "value1": "={{ $binary.data.fileExtension }}",
    "rules": {
      "rules": [
        {
          "value2": "pdf",
          "operation": "equal",
          "output": 1
        },
        {
          "value2": "png",
          "operation": "equal",
          "output": 2
        }
      ]
    }
  }
}
```

### Parallel Processing with Switch Nodes

Route different data types for specialized processing:

```
Email Input ‚Üí Extract Attachments ‚Üí Switch (by file type) ‚Üí PDF Processor
                                                         ‚Üí Image Analyzer
                                                         ‚Üí Document Parser
                                  ‚Üí Merge Results ‚Üí Send Summary
```

### Data Aggregation Patterns

**Aggregate from Multiple Processing Paths**:

```javascript
// Merge results from parallel processing
const pdfResults = $('PDF Processor').all();
const imageResults = $('Image Analyzer').all();
const docResults = $('Document Parser').all();

return [{
  totalProcessed: pdfResults.length + imageResults.length + docResults.length,
  results: {
    pdfs: pdfResults,
    images: imageResults,
    documents: docResults
  },
  summary: generateSummary([...pdfResults, ...imageResults, ...docResults])
}];
```

### Advanced Merge Strategies

**Enrichment Pattern**: Add AI-generated data to existing records
```json
{
  "name": "Enrich with AI",
  "type": "n8n-nodes-base.merge",
  "parameters": {
    "mode": "combine",
    "joinMode": "enrichInput2",
    "mergeByFields": {
      "values": [
        {
          "field1": "id",
          "field2": "recordId"
        }
      ]
    }
  }
}
```

### Code Node Patterns for Complex Logic

**Dynamic Data Transformation**:
```javascript
// Handle multiple data formats dynamically
const items = $input.all();

return items.map(item => {
  const json = item.json;
  
  // Normalize different field names
  const normalized = {
    id: json.id || json.ID || json.identifier,
    name: json.name || json.Name || json.company || json.Company,
    email: json.email || json.Email || json.recipient || json.Recipient,
    data: json
  };
  
  // Add processing metadata
  normalized.processedAt = new Date().toISOString();
  normalized.workflowRun = $execution.id;
  
  return { json: normalized };
});
```

## Latest Features (2025)

n8n's AI Agent capabilities continue to evolve rapidly, with several notable recent additions:

1. **Evaluations for AI Workflows**: Test and compare changes across multiple inputs before deployment
2. **Partial Execution for AI Tools**: Run and test specific tools without executing the entire agent workflow
3. **Extended HTTP Request Tool**: Full access to all HTTP Request node features from AI tools
4. **Model Context Protocol (MCP)**: Standardized protocol for AI model interactions with tools
5. **Scoped API Keys**: Create API keys with specific permissions for security

These features significantly enhance the development experience, security, and production reliability of AI Agent workflows.

## System Message Templates

Based on analysis of successful implementations, here are proven system message patterns:

### General Purpose Assistant
```
You are a helpful AI assistant created to help users with various tasks.
Current date and time: {{ DateTime.local().toFormat('cccc d LLLL yyyy, HH:mm') }}

Key Behaviors:
- Be concise but thorough in your responses
- Ask clarifying questions when needed
- Use tools when appropriate to provide accurate information
- Always maintain a professional and helpful tone

Available Tools:
[List your tools and when to use them]
```

### Customer Support Agent
```
You are a customer support representative for [COMPANY NAME].
Your primary goal is to resolve customer inquiries efficiently and professionally.

Guidelines:
- Always greet customers warmly
- Listen carefully to their concerns
- Use available tools to look up account information
- Escalate complex issues when necessary
- Follow up to ensure satisfaction

Available Tools:
1. order_lookup: Use when customers ask about order status
2. account_info: Use to retrieve customer account details
3. knowledge_base: Search for product information and FAQs
```

### Research Assistant
```
You are a research assistant designed to help users find, analyze, and synthesize information.
Current date: {{ DateTime.local().toFormat('cccc d LLLL yyyy') }}

Your capabilities:
- Conduct thorough web research using available tools
- Analyze and summarize findings
- Provide citations and sources
- Identify key insights and patterns

Research Process:
1. Understand the research question
2. Use search tools to gather information
3. Analyze and cross-reference sources
4. Provide structured summary with citations
```

## Tool Configuration Best Practices

### Dynamic Parameter Extraction
Use `$fromAI()` function for extracting values from conversation:

```json
{
  "parameters": {
    "query": "SELECT * FROM orders WHERE order_id = '{{ $fromAI('order_id', 'Customer order number or ID') }}'",
    "options": {
      "start_date": "={{ $fromAI('start_date', 'Start date in YYYY-MM-DD format') }}",
      "end_date": "={{ $fromAI('end_date', 'End date in YYYY-MM-DD format') }}"
    }
  }
}
```

### Tool Descriptions
Write clear, actionable descriptions that help the AI understand when and how to use each tool:

**Good Example:**
```
"Use this tool to look up customer order status by order number. Requires a valid order number (format: ORD-12345). Returns order status, shipping info, and estimated delivery."
```

**Poor Example:**
```
"Gets order info"
```

## Production Deployment Checklist

### Pre-Deployment
- [ ] Test all credential connections
- [ ] Validate system messages with real scenarios
- [ ] Test tool functionality end-to-end
- [ ] Test sub-workflows independently
- [ ] Validate flow control logic with edge cases
- [ ] Implement proper error handling
- [ ] Set up monitoring and logging
- [ ] Configure appropriate memory settings
- [ ] Test with multiple concurrent users (if applicable)
- [ ] Add comprehensive sticky note documentation
- [ ] Test data volume limits (Google Sheets 50k char limit)
- [ ] Implement workflow static data pattern for large datasets
- [ ] Test multi-stage agent handoffs
- [ ] Validate field name detection logic
- [ ] Test binary data processing paths

### Workflow Organization
- [ ] Use sub-workflows for complex, reusable logic
- [ ] Implement proper flow control for conditional processing
- [ ] Add sticky notes for setup instructions and documentation
- [ ] Name nodes clearly and consistently
- [ ] Group related functionality logically
- [ ] Test batch processing with realistic data volumes

### Memory Management for Production
- Use database-backed memory (Postgres/Redis) for multi-user scenarios
- Implement session cleanup for inactive users
- Monitor memory usage and costs
- Set appropriate context window limits

### Security Considerations
- Use scoped API keys with minimal required permissions
- Implement rate limiting for public endpoints
- Sanitize user inputs in tool parameters
- Never expose sensitive credentials in logs
- Implement user authentication for private workflows
- Validate sub-workflow access permissions

### Performance Optimization
- Choose appropriate model sizes for your use case
- Optimize system messages for token efficiency
- Implement caching for frequently accessed data
- Use parallel processing where possible
- Monitor and optimize tool execution times
- Use batch processing for large datasets
- Optimize sub-workflow calls to avoid unnecessary overhead

## Conclusion

The AI Agent node in n8n represents a powerful tool for building intelligent automation workflows that combine the reasoning capabilities of large language models with the action-taking abilities of traditional automation. By understanding the architecture, configuration options, and best practices outlined in this guide, plus leveraging the extensive template library, you can create sophisticated AI-powered solutions that integrate seamlessly with your existing systems and processes.

With 330+ real-world examples available in the template library, you have proven patterns for virtually any use case. Start with simpler templates and gradually build complexity as you become more familiar with the platform.

As the technology continues to evolve, staying updated with the latest features and patterns will ensure your AI Agent implementations remain effective and efficient. The modular nature of n8n's approach provides the flexibility to adapt to changing requirements while maintaining a consistent workflow architecture.

<div style="text-align: center">‚ÅÇ</div>

[^1]: https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/

[^2]: https://docs.n8n.io/advanced-ai/examples/understand-agents/

[^3]: https://docs.n8n.io/advanced-ai/

[^4]: https://community.n8n.io/t/best-practice-for-building-ai-agent-tools-built-in-nodes-or-call-workflow/114224/3

[^5]: https://www.youtube.com/watch?v=2SUPiNmLWdA

[^6]: https://www.youtube.com/watch?v=lSwMtsm6oDU

[^7]: https://community.n8n.io/t/getting-ai-agent-to-send-data-to-a-workflow-tool/42078

[^8]: https://www.reddit.com/r/n8n/comments/1liond2/dont_use_ai_agent_node_in_n8n/

[^9]: https://www.youtube.com/watch?v=ZbIVOy_GPyQ

[^10]: https://www.youtube.com/watch?v=J6sq2q7neLE

[^11]: https://www.youtube.com/watch?v=o2Pubq36Pao

[^12]: https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.youtube/

[^13]: https://docsbot.ai/prompts/technical/n8ncloud-ai-agents-setup

[^14]: https://n8n.io/workflows/4316-reliable-ai-agent-output-without-structured-output-parser-w-openai-and-switch/

[^15]: https://www.chaindesk.ai/tools/youtube-summarizer/n8-n-full-tutorial-easy-google-ai-agent-in-2025-for-beginners-no-code-ExBnzrlkt00

[^16]: https://www.youtube.com/watch?v=8YEsTdVDBr4

[^17]: https://n8n.io/ai/

[^18]: https://n8n.io/integrations/agent/

[^19]: https://docs.n8n.io/advanced-ai/examples/understand-tools/

[^20]: https://www.youtube.com/watch?v=zqUJtv8Uo_4

[^21]: https://docs.n8n.io/advanced-ai/examples/introduction/

[^22]: https://www.youtube.com/watch?v=ZGfLbM-6Dac\&vl=ru

[^23]: https://github.com/ContractorKeith/n8n-templates

[^24]: https://www.geeky-gadgets.com/ai-agent-tools-for-n8n-automation/

[^25]: https://community.n8n.io/t/ai-agent-http-tools-passing-params-in-json/77902

[^26]: https://docs.n8n.io/advanced-ai/examples/using-the-fromai-function/

[^27]: https://community.n8n.io/t/apologies-help-needed-n8n-ai-agent-node-with-dynamic-json-to-xlsx/81615

[^28]: https://www.reddit.com/r/n8n/comments/1jbo4wm/how_do_i_make_the_agent_see_the_entire_input_of/

[^29]: https://community.n8n.io/t/missing-agent-type-field-in-ai-agent-node-self-hosted-n8n-1-82-2/90377

[^30]: https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/plan-execute-agent/

[^31]: https://community.n8n.io/t/http-request-node-json-text-issue-for-sending-output-of-ai-agent-to-a-google-docs-file/113187

[^32]: https://www.youtube.com/watch?v=w6ZJzP0RBxY

[^33]: https://n8n.io/workflows/1954-ai-agent-chat/

[^34]: https://community.n8n.io/t/how-do-i-provide-agent-ai-example-json-without-causing-single-in-template-error/69960

[^35]: https://blog.n8n.io/how-to-build-ai-agent/

[^36]: https://www.youtube.com/watch?v=zr98hNrBjCE

[^37]: https://docsbot.ai/prompts/technical/n8n-agent-workflows

[^38]: https://github.com/akagelks/n8n-templates2

[^39]: https://n8n.io/workflows/2872-ai-agent-chatbot-long-term-memory-note-storage-telegram/

[^40]: https://community.n8n.io/t/how-to-properly-reset-ai-agent-memory-and-handle-different-customer-personalities/83399

[^41]: https://empathyfirstmedia.com/12-best-n8n-ai-agents-to-build-ai-workflows-2025/

[^42]: https://community.n8n.io/t/persisting-session-variables-in-n8n-workflows-for-ai-agents-using-postgres-memory/89437

[^43]: https://www.geeky-gadgets.com/n8n-ai-agent-optimization-guide/

[^44]: https://substack.com/@huryn/note/c-114334916

[^45]: https://alfrednutile.info/2025/02/25/build-an-ai-agent-that-actually-remembers-you-n8n-tutorial/

[^46]: https://www.youtube.com/watch?v=T_aIvAuhEGY

[^47]: https://generect.com/blog/n8n-mcp/

[^48]: https://www.rickkadlac.com/p/exploring-ai-agent-possibilities

[^49]: https://www.youtube.com/watch?v=mbQsnrxHPwE

[^50]: https://n8n.io/integrations/categories/ai/model-context-protocol/

[^51]: https://www.youtube.com/watch?v=hPBldzJHobo

[^52]: https://www.lindy.ai/blog/n8n-ai-agents

[^53]: https://docs.n8n.io/release-notes/

[^54]: https://community.n8n.io/t/provide-and-use-model-context-protocol/63799

[^55]: https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/common-issues/

[^56]: https://community.n8n.io/t/trouble-with-ai-agents/51827

[^57]: https://www.reddit.com/r/n8n/comments/1jv5ayd/ai_agent_issues/

[^58]: https://community.n8n.io/t/ai-agent-problem/110515

[^59]: https://nguyenthanhluan.com/en/glossary/ai-agent-node-common-issues-en/

[^60]: https://smythos.com/ai-agents/comparison/n8n-vs-openagents/

[^61]: https://www.reddit.com/r/n8n/comments/1klfrt6/help_with_n8n_ai_agent_tool_performance_issue/

[^62]: https://www.theaiautomators.com/level-up-your-ai-agents-with-fine-tuning/

[^63]: https://www.youtube.com/watch?v=kEtYJOijCBM

[^64]: https://www.youtube.com/watch?v=wFaEja4io-E

[^65]: https://github.com/Sylvester-dev/awesome-n8n-templates-2

[^66]: https://docs.n8n.io/advanced-ai/langchain/langchain-n8n/

[^67]: https://docs.n8n.io/advanced-ai/intro-tutorial/

[^68]: https://community.n8n.io/t/best-practice-for-building-ai-agent-tools-built-in-nodes-or-call-workflow/114224

[^69]: https://community.n8n.io/t/function-call-in-ai-agent/87907

[^70]: https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-langchain.openai/

[^71]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/d41aa3decf7b0d4044411f03bbd8197b/9b1fbead-2861-44e9-963a-bb31c25d0e08/87a23477.csv

[^72]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/d41aa3decf7b0d4044411f03bbd8197b/e5d17e6d-92ee-4d73-814c-c01219473cf3/600247fa.json

[^73]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/d41aa3decf7b0d4044411f03bbd8197b/07179fad-cbb2-484d-a4c6-b34ba9938362/07aca1f1.csv

